# lightning.pytorch==2.1.1
seed_everything: 0
trainer:
  accelerator: auto
  strategy: auto
  devices: auto
  num_nodes: 2
  precision: 16-mixed
  logger: True # will use tensorboardlogger
  callbacks:
    # - class_path: RichProgressBar
    - class_path: NewLineProgressBar
    - class_path: LearningRateMonitor
      init_args:
        logging_interval: epoch
    - class_path: ModelCheckpoint
      init_args:
        filename: "{epoch}"
        monitor: val/loss
        save_last: True
        enable_version_counter: False
        save_top_k: 5
  max_epochs: 200
  check_val_every_n_epoch: 1
  log_every_n_steps: 1
  enable_checkpointing: true
  default_root_dir: </DEFAULT_ROOT_DIR/>
data:
  # class_path: GenericNonGeoSegmentationDataModule
  class_path: Sen4MapDataset.LucasS2DataModule
  init_args:
    batch_size: 10
    num_workers: 16
    prefetch_factor: 5
    # constant_scale: 0.0001
    train_hdf5_path: </DATA_OR_KEY_DIRECTORY/>/train.h5
    train_hdf5_keys_path: </DATA_OR_KEY_DIRECTORY/>/train_keys.pkl
    test_hdf5_path: </DATA_OR_KEY_DIRECTORY/>/test.h5
    test_hdf5_keys_path: </DATA_OR_KEY_DIRECTORY/>/test_keys.pkl
    val_hdf5_path: </DATA_OR_KEY_DIRECTORY/>/val.h5
    val_hdf5_keys_path: </DATA_OR_KEY_DIRECTORY/>/val_keys.pkl
    dataset_bands:
      - BLUE
      - GREEN
      - RED
      - RED_EDGE_1
      - RED_EDGE_2
      - RED_EDGE_3
      - NIR_BROAD
      - NIR_NARROW
      - SWIR_1
      - SWIR_2
    input_bands:
      - BLUE
      - GREEN
      - RED
      - RED_EDGE_1
      - RED_EDGE_2
      - RED_EDGE_3
      - NIR_BROAD
      - NIR_NARROW
      - SWIR_1
      - SWIR_2
    crop_size: 15
    train_shuffle: True
    resize: True
    resize_to:
      - 224
      - 224
    resize_interpolation: bilinear
    # rgb_indices:
    #   - 2
    #   - 1
    #   - 0
    # train_data_root: <senfloods_root>/senfloods/v1.1/data/flood_events/HandLabeled/S2Hand/
    # train_label_data_root: <senfloods_root>/senfloods/v1.1/data/flood_events/HandLabeled/LabelHand
    # val_data_root: <senfloods_root>/senfloods/v1.1/data/flood_events/HandLabeled/S2Hand/
    # val_label_data_root: <senfloods_root>/senfloods/v1.1/data/flood_events/HandLabeled/LabelHand
    # test_data_root: <senfloods_root>/senfloods/v1.1/data/flood_events/HandLabeled/S2Hand/
    # test_label_data_root: <senfloods_root>/senfloods/v1.1/data/flood_events/HandLabeled/LabelHand
    # # these must be obtained by running terratorch/examples/scripts/convert_sen1floods11_splits.py on the original split csv files
    # train_split: <senfloods_root>/senfloods/v1.1/splits/flood_handlabeled/flood_train_data.txt
    # test_split: <senfloods_root>/senfloods/v1.1/splits/flood_handlabeled/flood_test_data.txt
    # val_split: <senfloods_root>/senfloods/v1.1/splits/flood_handlabeled/flood_valid_data.txt
    # img_grep: "*_S2Hand.tif"
    # label_grep: "*_LabelHand.tif"
    # no_label_replace: -1
    # no_data_replace: 0
    # means:
    #   - 0.107582
    #   - 0.13471393
    #   - 0.12520133
    #   - 0.3236181
    #   - 0.2341743
    #   - 0.15878009
    # stds:
    #   - 0.07145836
    #   - 0.06783548
    #   - 0.07323416
    #   - 0.09489725
    #   - 0.07938496
    #   - 0.07089546
    # num_classes: 2
model:
  class_path: Sen4MapDataset.CustomClassificationTask
  init_args:
    model_args:
      decoder: IdentityDecoder
      pretrained: true
      backbone: prithvi_vit_600
      backbone_pretrained_cfg_overlay:
        file: </Prithvi-2.0-600M.pt>
      backbone_patch_size: 14
      backbone_pretrain_img_size: 224
      # backbone_tubelet_size: 3
      # decoder_channels: 256
      head_dim_list:
        - 384
        - 128
      in_channels: 10
      bands:
        - BLUE
        - GREEN
        - RED
        - RED_EDGE_1
        - RED_EDGE_2
        - RED_EDGE_3
        - NIR_BROAD
        - NIR_NARROW
        - SWIR_1
        - SWIR_2
      num_frames: 12
      num_classes: 10
      head_dropout: 0.1
      # decoder_num_convs: 4
      # head_channel_list:
      #   - 256
    loss: ce
    # aux_heads:
    #   - name: aux_head
    #     decoder: FCNDecoder
    #     decoder_args:
    #       decoder_channels: 256
    #       decoder_in_index: -1
    #       decoder_num_convs: 2
    #       head_dropout: 0.1
    #       # head_channel_list:
    #       #   - 64
    # aux_loss:
    #   aux_head: 1.0
    # ignore_index: -1
    # class_weights:
    #   - 0.3
    #   - 0.7
    freeze_backbone: false
    # freeze_decoder: false
    model_factory: PrithviModelFactory


  # class_path: terratorch.tasks.ClassificationTask
  # init_args:
  #   model_args:
  #     decoder: IdentityDecoder
  #     pretrained: true
  #     backbone: prithvi_vit_100
  #     head_dim_list:
  #       - 384
  #       - 128
  #     in_channels: 6
  #     bands:
  #       - BLUE
  #       - GREEN
  #       - RED
  #       - NIR_NARROW
  #       - SWIR_1
  #       - SWIR_2
  #     num_frames: 1
  #     num_classes: 10
  #     head_dropout: 0.1
  #   loss: ce
  #   freeze_backbone: false
  #   model_factory: PrithviModelFactory


optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 6.e-5
    weight_decay: 0.05
lr_scheduler:
  class_path: ReduceLROnPlateau
  init_args:
    monitor: val/loss

# Virkar EKKI:
# StateDictModelCheckpoint:
#   every_n_train_steps: 100
# ModelCheckpoint:
#   every_n_train_steps: 100